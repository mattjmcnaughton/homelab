---
services:
  open-webui-postgres:
    image: ${CONTAINER_REGISTRY:-docker.io}/pgvector/pgvector:pg16
    restart: unless-stopped
    volumes:
      - /mnt/data/open-webui-postgres-data:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5
    network_mode: service:tailscale
    user: "1000:1000"
    cap_drop:
      - ALL

  open-webui-tika:
    image: ${CONTAINER_REGISTRY:-docker.io}/apache/tika:latest-full
    restart: unless-stopped
    network_mode: service:tailscale
    healthcheck:
      # Switch to an actual network request once we have curl/wget installed.
      test: ["CMD", "ls"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s
    user: "1000:1000"
    cap_drop:
      - ALL

  open-webui:
    image: ${CONTAINER_REGISTRY:-ghcr.io}/open-webui/open-webui:v0.6.7
    restart: unless-stopped
    depends_on:
      open-webui-postgres:
        condition: service_healthy
      open-webui-tika:
        condition: service_healthy
    volumes:
      - /mnt/data/open-webui-open-webui-data:/app/backend/data
    environment:
      # https://docs.openwebui.com/getting-started/env-configuration/

      # TBD if necessary... might be an ollama variable.
      - HF_HUB_OFFLINE=1

      - OPENAI_API_BASE_URL=${OPENAI_API_BASE_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}

      - IMAGE_GENERATION_ENGINE=openai
      - ENABLE_IMAGE_GENERATION=True
      - IMAGES_OPENAI_API_BASE_URL=${OPENAI_API_BASE_URL}
      - IMAGES_OPENAI_API_KEY=${OPENAI_API_KEY}

      - RAG_EMBEDDING_ENGINE=openai
      - RAG_EMBEDDING_MODEL=local-nomic-embed-text
      - PDF_EXTRACT_IMAGES=True
      - RAG_OPENAI_API_BASE_URL=${OPENAI_API_BASE_URL}
      - RAG_OPENAI_API_KEY=${OPENAI_API_KEY}
      - CONTENT_EXTRACTION_ENGINE=tika
      - TIKA_SERVER_URL=http://localhost:9998

      # For now, we share a single db for PGVECTOR and "vanilla" postgres. We
      # could change this later.
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@localhost:5432/${POSTGRES_DB}

      - VECTOR_DB=pgvector
      - PGVECTOR_MAX_DIMENSION=1536

      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}

      - ENABLE_CODE_EXECUTION=False
      - ENABLE_CODE_INTERPRETER=False
      - ENABLE_WEB_SEARCH=False

      - WEBUI_SESSION_COOKIE_SAME_SITE=strict
      - WEBUI_SESSION_COOKIE_SECURE=True

      - OFFLINE_MODE=True
      - DISABLE_TELEMETRY=True
      - DISABLE_USAGE_STATS=True
    healthcheck:
      # Switch to an actual network request once we have curl/wget installed.
      test: ["CMD", "ls"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s
    user: "1000:1000"
    cap_drop:
      - ALL
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M
    network_mode: service:tailscale

  tailscale:
    image: tailscale/tailscale:latest
    restart: unless-stopped
    hostname: open-webui
    volumes:
      - tailscale-tmp:/tmp
    environment:
      - TS_HOSTNAME={{ service_name }}
      - TS_USERSPACE=true
      - TS_EXTRA_ARGS=--advertise-tags={{ tailscale_advertise_tags_arg }}
      - TS_SOCKET=/tmp/tailscaled.sock
    cap_add:
      - NET_ADMIN
    env_file:
      - .env.tailscale
    networks:
      - internal

  caddy:
    image: caddy:2-alpine
    restart: unless-stopped
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - /mnt/data/open-webui-caddy-data:/data
      - caddy-config-tmp:/config
      - tailscale-tmp:/var/run/tailscale
    depends_on:
      - open-webui
    network_mode: service:tailscale

networks:
  internal:
    driver: bridge

volumes:
  caddy-config-tmp:
  tailscale-tmp:
